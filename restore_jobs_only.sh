#!/bin/bash

# åªæ¢å¤jobsæ•°æ®çš„è„šæœ¬

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}å¼€å§‹æ¢å¤å†å²jobsæ•°æ®...${NC}"

# å¯åŠ¨ä¸´æ—¶PostgreSQLå®¹å™¨
echo -e "${YELLOW}å¯åŠ¨ä¸´æ—¶PostgreSQLå®¹å™¨...${NC}"
docker run --name temp_postgres_old --rm -d \
    -v ai-asmr-veo3-batch_postgres-db-volume:/var/lib/postgresql/data \
    -e POSTGRES_USER=airflow \
    -e POSTGRES_PASSWORD=airflow \
    -e POSTGRES_DB=airflow \
    postgres:13

echo -e "${BLUE}ç­‰å¾…PostgreSQLå¯åŠ¨...${NC}"
sleep 10

# å¯¼å‡ºå†å²jobsæ•°æ®
echo -e "${BLUE}å¯¼å‡ºå†å²jobsæ•°æ®...${NC}"
docker exec temp_postgres_old psql -U airflow -d airflow -c "
SELECT 
    id,
    prompt_text,
    status,
    job_type,
    COALESCE(local_path, ''),
    COALESCE(gcs_uri, ''),
    created_at,
    updated_at
FROM jobs 
ORDER BY id;
" > historical_jobs_data.txt

# æ£€æŸ¥å¯¼å‡ºçš„æ•°æ®
if [ -s historical_jobs_data.txt ]; then
    echo -e "${GREEN}âœ… æˆåŠŸå¯¼å‡ºå†å²æ•°æ®${NC}"
    JOB_COUNT=$(grep -c "^[0-9]" historical_jobs_data.txt)
    echo -e "${BLUE}å†å²ä½œä¸šæ•°é‡: $JOB_COUNT${NC}"
else
    echo -e "${RED}âŒ å¯¼å‡ºå†å²æ•°æ®å¤±è´¥${NC}"
    docker stop temp_postgres_old
    exit 1
fi

# å¤‡ä»½å½“å‰æ•°æ®
echo -e "${BLUE}å¤‡ä»½å½“å‰æ•°æ®...${NC}"
./backup_database.sh

# æ¸…ç†å½“å‰jobsè¡¨
echo -e "${YELLOW}æ¸…ç†å½“å‰jobsè¡¨...${NC}"
docker compose exec postgres psql -U airflow -d airflow -c "TRUNCATE TABLE jobs RESTART IDENTITY;"

# å¯¼å…¥å†å²æ•°æ®
echo -e "${BLUE}å¯¼å…¥å†å²æ•°æ®...${NC}"
while IFS='|' read -r id prompt_text status job_type local_path gcs_uri created_at updated_at; do
    # è·³è¿‡æ ‡é¢˜è¡Œå’Œç©ºè¡Œ
    if [[ "$id" =~ ^[0-9]+$ ]]; then
        # è½¬ä¹‰å•å¼•å·
        prompt_text=$(echo "$prompt_text" | sed "s/'/''/g")
        local_path=$(echo "$local_path" | sed "s/'/''/g")
        gcs_uri=$(echo "$gcs_uri" | sed "s/'/''/g")
        
        docker compose exec postgres psql -U airflow -d airflow -c "
        INSERT INTO jobs (id, prompt_text, status, job_type, local_path, gcs_uri, created_at, updated_at)
        VALUES ($id, '$prompt_text', '$status', '$job_type', '$local_path', '$gcs_uri', '$created_at', '$updated_at');
        "
    fi
done < historical_jobs_data.txt

# éªŒè¯å¯¼å…¥ç»“æœ
echo -e "${BLUE}éªŒè¯å¯¼å…¥ç»“æœ...${NC}"
JOB_COUNT=$(docker compose exec postgres psql -U airflow -d airflow -t -c "SELECT COUNT(*) FROM jobs;")
echo -e "${GREEN}âœ… æˆåŠŸå¯¼å…¥ $JOB_COUNT ä¸ªå†å²ä½œä¸š${NC}"

# æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
echo -e "${BLUE}ä½œä¸šçŠ¶æ€ç»Ÿè®¡:${NC}"
docker compose exec postgres psql -U airflow -d airflow -c "
SELECT 
    job_type,
    status,
    COUNT(*) as count
FROM jobs 
GROUP BY job_type, status 
ORDER BY job_type, status;
"

# æ¢å¤æ—¥å¿—æ–‡ä»¶
echo -e "${BLUE}æ¢å¤å†å²æ—¥å¿—...${NC}"
mkdir -p logs/historical_backup

# å¤åˆ¶å†å²æ—¥å¿—
docker run --rm \
    -v dev_airflow_logs:/old_logs \
    -v "$(pwd)/logs/historical_backup:/backup" \
    alpine sh -c "cp -r /old_logs/* /backup/ 2>/dev/null || echo 'æ— æ³•å¤åˆ¶æ—¥å¿—æ–‡ä»¶'"

echo -e "${GREEN}âœ… å†å²æ—¥å¿—å·²å¤‡ä»½åˆ° logs/historical_backup/${NC}"

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo -e "${BLUE}æ¸…ç†ä¸´æ—¶æ–‡ä»¶...${NC}"
rm -f historical_jobs_data.txt

# åœæ­¢ä¸´æ—¶å®¹å™¨
echo -e "${BLUE}åœæ­¢ä¸´æ—¶å®¹å™¨...${NC}"
docker stop temp_postgres_old

echo -e "${GREEN}ğŸ‰ å†å²jobsæ•°æ®æ¢å¤å®Œæˆï¼${NC}"
echo -e "${BLUE}ç°åœ¨å¯ä»¥è®¿é—®:${NC}"
echo -e "${GREEN}  - Prompt Manager: http://localhost:5001${NC}"
echo -e "${GREEN}  - Airflow: http://localhost:8081${NC}"
echo -e "${BLUE}å†å²æ—¥å¿—ä½ç½®: logs/historical_backup/${NC}" 